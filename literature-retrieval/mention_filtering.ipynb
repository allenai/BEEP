{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bd7815c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import pickle\n",
    "import csv\n",
    "from nltk import word_tokenize, sent_tokenize\n",
    "import spacy\n",
    "from spacy.tokens.doc import Doc\n",
    "from spacy.tokens import Span\n",
    "import medspacy\n",
    "from medspacy.context import ConTextComponent, ConTextRule\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "85122540",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-sm==3.1.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.1.0/en_core_web_sm-3.1.0-py3-none-any.whl (13.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 13.6 MB 10.9 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: spacy<3.2.0,>=3.1.0 in /net/nfs2.s2-research/aakankshan/miniconda3/envs/med-env/lib/python3.8/site-packages (from en-core-web-sm==3.1.0) (3.1.6)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /net/nfs2.s2-research/aakankshan/miniconda3/envs/med-env/lib/python3.8/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (0.7.7)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /net/nfs2.s2-research/aakankshan/miniconda3/envs/med-env/lib/python3.8/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (2.15.1)\n",
      "Requirement already satisfied: pathy>=0.3.5 in /net/nfs2.s2-research/aakankshan/miniconda3/envs/med-env/lib/python3.8/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (0.6.1)\n",
      "Requirement already satisfied: click<8.1.0 in /net/nfs2.s2-research/aakankshan/miniconda3/envs/med-env/lib/python3.8/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (8.0.4)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.8 in /net/nfs2.s2-research/aakankshan/miniconda3/envs/med-env/lib/python3.8/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (3.0.9)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /net/nfs2.s2-research/aakankshan/miniconda3/envs/med-env/lib/python3.8/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (2.0.6)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /net/nfs2.s2-research/aakankshan/miniconda3/envs/med-env/lib/python3.8/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (3.0.6)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /net/nfs2.s2-research/aakankshan/miniconda3/envs/med-env/lib/python3.8/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (1.20.2)\n",
      "Requirement already satisfied: setuptools in /net/nfs2.s2-research/aakankshan/miniconda3/envs/med-env/lib/python3.8/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (61.2.0)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /net/nfs2.s2-research/aakankshan/miniconda3/envs/med-env/lib/python3.8/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (2.0.7)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /net/nfs2.s2-research/aakankshan/miniconda3/envs/med-env/lib/python3.8/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (4.64.0)\n",
      "Requirement already satisfied: jinja2 in /net/nfs2.s2-research/aakankshan/miniconda3/envs/med-env/lib/python3.8/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (3.1.1)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in /net/nfs2.s2-research/aakankshan/miniconda3/envs/med-env/lib/python3.8/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (1.8.2)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in /net/nfs2.s2-research/aakankshan/miniconda3/envs/med-env/lib/python3.8/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (0.9.1)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.1 in /net/nfs2.s2-research/aakankshan/miniconda3/envs/med-env/lib/python3.8/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (2.4.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /net/nfs2.s2-research/aakankshan/miniconda3/envs/med-env/lib/python3.8/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (21.3)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /net/nfs2.s2-research/aakankshan/miniconda3/envs/med-env/lib/python3.8/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (1.0.6)\n",
      "Requirement already satisfied: thinc<8.1.0,>=8.0.12 in /net/nfs2.s2-research/aakankshan/miniconda3/envs/med-env/lib/python3.8/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (8.0.15)\n",
      "Requirement already satisfied: typer<0.5.0,>=0.3.0 in /net/nfs2.s2-research/aakankshan/miniconda3/envs/med-env/lib/python3.8/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (0.4.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /net/nfs2.s2-research/aakankshan/miniconda3/envs/med-env/lib/python3.8/site-packages (from packaging>=20.0->spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (3.0.8)\n",
      "Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in /net/nfs2.s2-research/aakankshan/miniconda3/envs/med-env/lib/python3.8/site-packages (from pathy>=0.3.5->spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (5.2.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /net/nfs2.s2-research/aakankshan/miniconda3/envs/med-env/lib/python3.8/site-packages (from pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4->spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (4.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /net/nfs2.s2-research/aakankshan/miniconda3/envs/med-env/lib/python3.8/site-packages (from jinja2->spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (2.1.1)\n",
      "Installing collected packages: en-core-web-sm\n",
      "Successfully installed en-core-web-sm-3.1.0\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "# Initialize ConText algorithm for negated entity detection\n",
    "!python -m spacy download en_core_web_sm\n",
    "import en_core_web_sm\n",
    "nlp = en_core_web_sm.load(disable=[\"tokenizer\",\"ner\"])\n",
    "# spacy.load(\"en_core_web_sm\", disable=[\"tokenizer\",\"ner\"])\n",
    "context = ConTextComponent(nlp, rules=\"default\", use_context_window=True, max_scope=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4177febf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add paths to files containing extracted mentions and raw texts here\n",
    "# In our pipeline, mentions are extracted using a model trained on the i2b2 2010 dataset\n",
    "mention_file = 'PATH TO MENTION EXTRACTOR OUTPUT'\n",
    "text_file = 'PATH TO RAW TEXTS'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6c22cc10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in mentions and raw texts\n",
    "texts = {}\n",
    "reader = csv.reader(open(text_file))\n",
    "next(reader, None)\n",
    "for row in reader:\n",
    "    texts[row[0]] = []\n",
    "    sents = sent_tokenize(row[1])\n",
    "    for sent in sents:\n",
    "        texts[row[0]].append(list(word_tokenize(sent)))\n",
    "\n",
    "mentions = pickle.load(open(mention_file, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e0fcef17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processsing file 181614 (0)\n",
      "31 mentions kept out of 32 for file 181614\n",
      "Processsing file 136342 (1)\n",
      "17 mentions kept out of 18 for file 136342\n",
      "Processsing file 199961 (2)\n",
      "18 mentions kept out of 20 for file 199961\n",
      "Processsing file 121438 (3)\n",
      "63 mentions kept out of 63 for file 121438\n",
      "Processsing file 194393 (4)\n",
      "5 mentions kept out of 5 for file 194393\n",
      "Processsing file 138531 (5)\n",
      "68 mentions kept out of 73 for file 138531\n",
      "Processsing file 180762 (6)\n",
      "31 mentions kept out of 33 for file 180762\n",
      "Processsing file 166330 (7)\n",
      "34 mentions kept out of 43 for file 166330\n",
      "Processsing file 170119 (8)\n",
      "70 mentions kept out of 77 for file 170119\n",
      "Processsing file 194148 (9)\n",
      "85 mentions kept out of 104 for file 194148\n",
      "Processsing file 196032 (10)\n",
      "4 mentions kept out of 4 for file 196032\n",
      "Processsing file 119472 (11)\n",
      "17 mentions kept out of 19 for file 119472\n",
      "Processsing file 133167 (12)\n",
      "6 mentions kept out of 7 for file 133167\n",
      "Processsing file 108023 (13)\n",
      "78 mentions kept out of 85 for file 108023\n",
      "Processsing file 184681 (14)\n",
      "73 mentions kept out of 77 for file 184681\n",
      "Processsing file 152028 (15)\n",
      "87 mentions kept out of 101 for file 152028\n",
      "Processsing file 166382 (16)\n",
      "22 mentions kept out of 28 for file 166382\n",
      "Processsing file 112273 (17)\n",
      "82 mentions kept out of 92 for file 112273\n",
      "Processsing file 116746 (18)\n",
      "31 mentions kept out of 34 for file 116746\n",
      "Processsing file 124660 (19)\n",
      "20 mentions kept out of 20 for file 124660\n",
      "Processsing file 140347 (20)\n",
      "116 mentions kept out of 121 for file 140347\n",
      "Processsing file 167148 (21)\n",
      "52 mentions kept out of 53 for file 167148\n",
      "Processsing file 177328 (22)\n",
      "23 mentions kept out of 23 for file 177328\n",
      "Processsing file 148213 (23)\n",
      "41 mentions kept out of 48 for file 148213\n",
      "Processsing file 133124 (24)\n",
      "110 mentions kept out of 116 for file 133124\n",
      "Processsing file 118649 (25)\n",
      "16 mentions kept out of 20 for file 118649\n",
      "Processsing file 158204 (26)\n",
      "52 mentions kept out of 54 for file 158204\n",
      "Processsing file 178289 (27)\n",
      "92 mentions kept out of 100 for file 178289\n",
      "Processsing file 169298 (28)\n",
      "54 mentions kept out of 71 for file 169298\n",
      "Processsing file 138432 (29)\n",
      "36 mentions kept out of 39 for file 138432\n",
      "Processsing file 174411 (30)\n",
      "43 mentions kept out of 48 for file 174411\n",
      "Processsing file 197776 (31)\n",
      "43 mentions kept out of 55 for file 197776\n",
      "Processsing file 102781 (32)\n",
      "28 mentions kept out of 28 for file 102781\n",
      "Processsing file 163814 (33)\n",
      "32 mentions kept out of 40 for file 163814\n",
      "Processsing file 182101 (34)\n",
      "56 mentions kept out of 68 for file 182101\n",
      "Processsing file 107930 (35)\n",
      "54 mentions kept out of 54 for file 107930\n",
      "Processsing file 161919 (36)\n",
      "41 mentions kept out of 42 for file 161919\n",
      "Processsing file 180569 (37)\n",
      "7 mentions kept out of 10 for file 180569\n",
      "Processsing file 137211 (38)\n",
      "43 mentions kept out of 44 for file 137211\n",
      "Processsing file 113853 (39)\n",
      "76 mentions kept out of 78 for file 113853\n",
      "Processsing file 104602 (40)\n",
      "33 mentions kept out of 34 for file 104602\n",
      "Processsing file 146549 (41)\n",
      "24 mentions kept out of 27 for file 146549\n",
      "Processsing file 105316 (42)\n",
      "31 mentions kept out of 32 for file 105316\n",
      "Processsing file 106592 (43)\n",
      "27 mentions kept out of 34 for file 106592\n",
      "Processsing file 119586 (44)\n",
      "39 mentions kept out of 44 for file 119586\n",
      "Processsing file 195418 (45)\n",
      "48 mentions kept out of 50 for file 195418\n",
      "Processsing file 199658 (46)\n",
      "73 mentions kept out of 90 for file 199658\n",
      "Processsing file 188278 (47)\n",
      "36 mentions kept out of 36 for file 188278\n",
      "Processsing file 105820 (48)\n",
      "50 mentions kept out of 60 for file 105820\n",
      "Processsing file 170331 (49)\n",
      "28 mentions kept out of 29 for file 170331\n",
      "Processsing file 140462 (50)\n",
      "82 mentions kept out of 84 for file 140462\n",
      "Processsing file 139120 (51)\n",
      "81 mentions kept out of 98 for file 139120\n",
      "Processsing file 197750 (52)\n",
      "58 mentions kept out of 69 for file 197750\n",
      "Processsing file 183942 (53)\n",
      "81 mentions kept out of 103 for file 183942\n",
      "Processsing file 147611 (54)\n",
      "33 mentions kept out of 34 for file 147611\n",
      "Processsing file 185307 (55)\n",
      "22 mentions kept out of 22 for file 185307\n",
      "Processsing file 122063 (56)\n",
      "33 mentions kept out of 38 for file 122063\n",
      "Processsing file 195290 (57)\n",
      "45 mentions kept out of 51 for file 195290\n",
      "Processsing file 146873 (58)\n",
      "88 mentions kept out of 104 for file 146873\n",
      "Processsing file 189279 (59)\n",
      "15 mentions kept out of 21 for file 189279\n",
      "Processsing file 130860 (60)\n",
      "86 mentions kept out of 88 for file 130860\n",
      "Processsing file 185263 (61)\n",
      "51 mentions kept out of 70 for file 185263\n",
      "Processsing file 142048 (62)\n",
      "51 mentions kept out of 66 for file 142048\n",
      "Processsing file 162085 (63)\n",
      "45 mentions kept out of 51 for file 162085\n",
      "Processsing file 163845 (64)\n",
      "134 mentions kept out of 148 for file 163845\n",
      "Processsing file 128096 (65)\n",
      "26 mentions kept out of 30 for file 128096\n",
      "Processsing file 184571 (66)\n",
      "32 mentions kept out of 41 for file 184571\n",
      "Processsing file 156733 (67)\n",
      "33 mentions kept out of 39 for file 156733\n",
      "Processsing file 154264 (68)\n",
      "47 mentions kept out of 55 for file 154264\n",
      "Processsing file 181896 (69)\n",
      "46 mentions kept out of 46 for file 181896\n",
      "Processsing file 175526 (70)\n",
      "24 mentions kept out of 32 for file 175526\n",
      "Processsing file 100375 (71)\n",
      "80 mentions kept out of 84 for file 100375\n",
      "Processsing file 190665 (72)\n",
      "99 mentions kept out of 106 for file 190665\n",
      "Processsing file 123366 (73)\n",
      "76 mentions kept out of 99 for file 123366\n",
      "Processsing file 181577 (74)\n",
      "40 mentions kept out of 43 for file 181577\n",
      "Processsing file 175894 (75)\n",
      "23 mentions kept out of 23 for file 175894\n",
      "Processsing file 136897 (76)\n",
      "73 mentions kept out of 80 for file 136897\n",
      "Processsing file 195649 (77)\n",
      "47 mentions kept out of 61 for file 195649\n",
      "Processsing file 135705 (78)\n",
      "66 mentions kept out of 76 for file 135705\n",
      "Processsing file 163848 (79)\n",
      "49 mentions kept out of 56 for file 163848\n",
      "Processsing file 142014 (80)\n",
      "18 mentions kept out of 21 for file 142014\n",
      "Processsing file 106993 (81)\n",
      "66 mentions kept out of 70 for file 106993\n",
      "Processsing file 142241 (82)\n",
      "130 mentions kept out of 156 for file 142241\n",
      "Processsing file 140334 (83)\n",
      "32 mentions kept out of 33 for file 140334\n",
      "Processsing file 184510 (84)\n",
      "96 mentions kept out of 105 for file 184510\n",
      "Processsing file 154087 (85)\n",
      "22 mentions kept out of 22 for file 154087\n",
      "Processsing file 163396 (86)\n",
      "124 mentions kept out of 155 for file 163396\n",
      "Processsing file 111067 (87)\n",
      "32 mentions kept out of 32 for file 111067\n",
      "Processsing file 167099 (88)\n",
      "41 mentions kept out of 42 for file 167099\n",
      "Processsing file 120211 (89)\n",
      "44 mentions kept out of 49 for file 120211\n",
      "Processsing file 190941 (90)\n",
      "40 mentions kept out of 43 for file 190941\n",
      "Processsing file 101061 (91)\n",
      "75 mentions kept out of 80 for file 101061\n",
      "Processsing file 161262 (92)\n",
      "64 mentions kept out of 70 for file 161262\n",
      "Processsing file 115813 (93)\n",
      "96 mentions kept out of 114 for file 115813\n",
      "Processsing file 140217 (94)\n",
      "18 mentions kept out of 18 for file 140217\n",
      "Processsing file 126999 (95)\n",
      "56 mentions kept out of 61 for file 126999\n",
      "Processsing file 174522 (96)\n",
      "83 mentions kept out of 96 for file 174522\n",
      "Processsing file 145593 (97)\n",
      "69 mentions kept out of 77 for file 145593\n",
      "Processsing file 192045 (98)\n",
      "48 mentions kept out of 55 for file 192045\n",
      "Processsing file 156866 (99)\n"
     ]
    }
   ],
   "source": [
    "# Apply ConText algorithm to identify and filter negated entities\n",
    "filtered_mentions = {}\n",
    "file_ind = 0\n",
    "for file in texts:\n",
    "    print('Processsing file {} ({})'.format(file, file_ind))\n",
    "    file_ind += 1\n",
    "    filtered_mentions[file] = {}\n",
    "    for i, line in enumerate(texts[file]):\n",
    "        cur_ment = mentions[file][i]\n",
    "        if not cur_ment:\n",
    "            continue\n",
    "        # If mentions are present in sentence, perform negation-based filtering\n",
    "        filtered_mentions[file][i] = []\n",
    "        doc = Doc(nlp.vocab, line)\n",
    "        for name, proc in nlp.pipeline:\n",
    "            doc = proc(doc)\n",
    "        entities = []\n",
    "        for mention in cur_ment:\n",
    "            entities.append(Span(doc, mention['start_offset'], mention['end_offset']+1, mention['pred_type']))\n",
    "        doc.ents = tuple(entities)\n",
    "        doc = context(doc)\n",
    "\n",
    "        for ent in doc.ents:\n",
    "            if ent._.is_negated:\n",
    "                continue\n",
    "            filtered_mentions[file][i].append({'mention': ent.text, 'start_offset': ent.start, 'end_offset': ent.end, 'pred_type': ent.label_})\n",
    "    all_mention_count = sum([len(y) for x,y in mentions[file].items()])\n",
    "    filtered_mention_count = sum([len(y) for x,y in filtered_mentions[file].items()])\n",
    "    print('{} mentions kept out of {} for file {}'.format(filtered_mention_count, all_mention_count, file))\n",
    "\n",
    "pickle.dump(filtered_mentions, open('PATH TO OUTPUT FILE', 'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (med-env)",
   "language": "python",
   "name": "med-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
